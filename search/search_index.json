{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"About The RAKI ILP Benchmark is a benchmark developed for the RAKI project. The benchmark aims to evaluate Explainable AI systems, by asking a system the best fitting concept for a Learning Problem. Thus the system aims to describe the problem as best it can using an OWL ontology. What is a Learning Problem in this context? A learning problem is a set of positive examples and negative examples, whereas one example is an Individual contained in the ABox of the benchmarked OWL ontology. A learning problem may have also a gold standard concept which describes the learning problem. How does it work? The RAKI ILP benchmark consists of two parts. The core part containing the actual API, and The Hobbit part containing the Hobbit workflow Core The Core evaluates a Learning problem and a corresponding concept, by retrieving all Individuals for this concept from the provided OWL Ontology and compares the retrieved individuals with the individuals stated in the Learning Problem. The Learning Problem may not contain all positives and negative individuals. However, the default is to check only against these individuals. That means all Individuals retrieved by the concept not occurring in either the positive nor the negative uris will be ignored. This can be avoided by using a gold standard concept and setting the useConcept flag. This allows to retrieve the individuals for the LearningProblem from the Ontology as well. For further Information on the API, have a look here Hobbit The RAKI ILP Benchmark is integrated into Hobbit . For further Information how the ILP benchmark works with Hobbit and a walkthrough on how to use it, have a look here Where can I find the code? The code is open source at https://github.com/dice-group/raki-ilp-benchmark and you can code with us if you want to :) Where do I submit a bug or enhancement? Please use the Github Issue Tracker at https://github.com/dice-group/raki-ilp-benchmark/issues","title":"About"},{"location":"#about","text":"The RAKI ILP Benchmark is a benchmark developed for the RAKI project. The benchmark aims to evaluate Explainable AI systems, by asking a system the best fitting concept for a Learning Problem. Thus the system aims to describe the problem as best it can using an OWL ontology.","title":"About"},{"location":"#what-is-a-learning-problem-in-this-context","text":"A learning problem is a set of positive examples and negative examples, whereas one example is an Individual contained in the ABox of the benchmarked OWL ontology. A learning problem may have also a gold standard concept which describes the learning problem.","title":"What is a Learning Problem in this context?"},{"location":"#how-does-it-work","text":"The RAKI ILP benchmark consists of two parts. The core part containing the actual API, and The Hobbit part containing the Hobbit workflow","title":"How does it work?"},{"location":"#core","text":"The Core evaluates a Learning problem and a corresponding concept, by retrieving all Individuals for this concept from the provided OWL Ontology and compares the retrieved individuals with the individuals stated in the Learning Problem. The Learning Problem may not contain all positives and negative individuals. However, the default is to check only against these individuals. That means all Individuals retrieved by the concept not occurring in either the positive nor the negative uris will be ignored. This can be avoided by using a gold standard concept and setting the useConcept flag. This allows to retrieve the individuals for the LearningProblem from the Ontology as well. For further Information on the API, have a look here","title":"Core"},{"location":"#hobbit","text":"The RAKI ILP Benchmark is integrated into Hobbit . For further Information how the ILP benchmark works with Hobbit and a walkthrough on how to use it, have a look here","title":"Hobbit"},{"location":"#where-can-i-find-the-code","text":"The code is open source at https://github.com/dice-group/raki-ilp-benchmark and you can code with us if you want to :) Where do I submit a bug or enhancement? Please use the Github Issue Tracker at https://github.com/dice-group/raki-ilp-benchmark/issues","title":"Where can I find the code?"},{"location":"api/","text":"We will describe the Core API in this section Learning Problem Description A learning problem is an object containing of a set of positive uris, negative uris and an optional concept. The positive uris as well as the negative uris are named individuals of the ABox of an OWL Ontology. The concept is a class expression representation of this problem. It is build by concepts of the TBox of the Ontology. The learning problem is described using JSON. An Example: { \"positives\" : [ \"http://ontology.com/individuals/Human1\" , \"http://ontology.com/individuals/Human3\" , \"http://ontology.com/individuals/Human7\" ], \"negatives\" : [ \"http://ontology.com/individuals/Bear1\" , \"http://ontology.com/individuals/Dragon1\" , \"http://ontology.com/individuals/Eagle1\" ], \"concept\" : \"ontology:Human\" } Why is the gold standard concept optional Be aware: a Learning Problem does not have to contain a Concept. Imagine the following Ontology Class Human Class Dragon Disjoint: Humand, Dragon Human1 is Human Dragon1 is Dragon Human2 is Human Our Learning problem is: positives: [\"Human1\"] negatives: [\"Human2\", \"Dragon1\"] There is no concept within the TBox of the ontology representing the Learning Problem fully. API Creating a Learning Problem A learning problem can be created using the LearningProblemFactory . We will define positives and negatives each as a Collection<String> for simplicity. These collections contain the positive and negative uris. Creating from Lists. LearningProblem problem = LearningProblemFactory . create ( positives , negatives ); Creating from JSON String String jsonString = \"{ \\\"positives\\\": [...], \\\"negatives\\\": [...] }\" LearningProblem problem = LearningProblemFactory . parse ( jsonString ); Creating multiple Learning Problems from JSON String String jsonString = \"[ { \\\"positives\\\": [...], \\\"negatives\\\": [...] }, { \\\"positives\\\": [...], \\\"negatives\\\": [...] }]\" Set < LearningProblem > problems = LearningProblemFactory . readMany ( jsonString ); Read learning Problems from file Set < LearningProblem > problems = LearningProblemFactory . readMany ( new File ( \"learningProblems.json\" )); Concepts - Manchester Parser Description A Concept is a Class Expression derived from the TBox of an OWL Ontology. F.e. Human or Dragon describes the Concept of all humans and dragons. The Format used in RAKI ILP is the Manchester Syntax. API The API has a ManchesterSyntaxParser . This parser allows to parse a Manchester Syntax String to an OWLClassExpression and rendering an OWLClassExpression to a Manchester Syntax String. It needs a main ontology, and an optional OWL base ontology (containing the basics of OWL, such as owl:Thing ). Furhter on it ManchesterSyntaxParser parser = new ManchesterSyntaxParser ( mainOntology , baseOntology ); OWLClassExpression expr = parser . parse ( \"ontology:Human or ontology:Dragon\" ); # concept = ' Human or Dragon ' String concept = parser . render ( expr ); Benchmark Configuration Description The Benchmark Configuration consists of three elements The benchmark name The file path containing the Ontology The file path containing the learning problems Configurations can be read from a YAML file or created simply by using the Configuration constructor The YAML file has to look like this datasets : - name : \"MyBenchmarkName1\" learningProblem : \"/path/to/learningProblems1.json\" dataset : \"/path/to/ontology1.owl\" - name : \"MyBenchmarkName2\" learningProblem : \"/path/to/learningProblems2.json\" dataset : \"/path/to/ontology2.owl\" The Learning problem has to be a json file. An example can be seen above. API Creating from file //load all Configurations Configurations confs = Configurations . load ( new File ( \"/path/to/config.yml\" )); //retrieve the ones with your benchmark name Configuration myBenchmark = confs . getConfiguration ( \"MyBenchmarkName1\" ); Using the Configuration to retrieve the OWLOntology and the Set of LearningProblems OWLOntology ontology = configuration . readOntology (); Set < LearningProblem > problems = configuration . readLearningProblems (); Metrics Currently, the core can calculate two metrics F1-Measure, Precision and Recall The Concept Length of a Concept F1-Measure The F1 measure will be calculated using the F1MeasureCalculator . The calculator will calculate the f1-score, precision and recall from the true positives , false positives and false negatives provided and stores the results internally as well to calculate the macro and micro f1 measure later on. Create an F1Result F1MeasureCalculator calculator = new F1MeasureCalculator (); F1Result result = calculator . addF1Measure ( truePositives , falsePositives , falseNegatives ); The results can then be queried from the F1Result object double precision = result . getPrecision (); double recall = result . getRecall (); double f1score = result . getF1measure (); Create macro and micro F1 scores F1MeasureCalculator calculator = new F1MeasureCalculator (); // Calculate and add the F1 scores for some truePositives, falsePositives and falseNegatives calculator . addF1Measure ( truePositives , falsePositives , falseNegatives ); calculator . addF1Measure ( truePositives , falsePositives , falseNegatives ); //the scores will be stored internally and be used to calculate the Micro and Macro F1Measures F1Result macroResults = calculator . calculateMacroF1Measure (); F1Result microResults = calculator . calculateMicroF1Measure (); To clear the stored values use the clear method calculator . clear (); Concept Length The concept length of an OWLClassExpression can be calculated by using the ConceptLengthCalculator . Currently, only the following syntax structures are supported: AND OR SOME ALL NOT ConceptLengthCalculator calculator = new ConceptLengthCalculator (); //Create your concept/class expression OWLClassExpression expr = ... ; calculator . render ( expr ); int lengthOfExpr = calculator . getConceptLength (); Evaluator Description The Evaluator evaluates a set of Learning problems against a set of concepts. Additionally, the Evaluator can evaluate a single Learning Problem against a single concept. The single evaluation will return a ResultContainer containing the F1 Measures and Concept Length. If either the Evaluator was used, by using a set of Learning Problem and Concept pairs or the single evaluation was executed multiple times, the Evaluator can return the Macro and Micro F1 measures as well as all concept lengths. It needs a main Ontology, the owl base Ontology (can be empty though) and if the gold standard concept should be used instead of the positive and negative uris inside the learning problems. API Create the evaluator boolean useConcepts = false ; Evaluator evaluator = new Evaluator ( mainOntology , owlBaseOntology , useConcepts ); Execute a single execution //create your learning problem LearningProblem problem = ...; //create the answer concept String concept = \"ontology:Human\" ResultContainer container = evaluator . evaluate ( learningProblem , concept ); int conceptLength = container . getConceptLength (); F1Result f1result = container . getF1Result (); Execute multiple LearningProblem, Concept pairs. Each Pair consists of a Learning Problem and the corresponding concept. //Create your problem Pairs Set < Pair < LearningProblem , String >> problemPairs = ...; evaluator . evaluate ( problemPairs ); //Now we can retrieve the macro and micro F1 measures, as well as all Concept Lengths as following F1Result macroF1 = evaluator . getMacroF1Measure (); F1Result microF1 = evaluator . getMicroF1Measure (); List < Integer > conceptLengths = evaluator . getConceptLengths (); Further on all available Metrics can be printed as a table to the standard output using: evaluator . printTable (); Table Printer The TablePrinter is a helper class to print a table in a kinda nice format. List < String > header = new ArrayList <> (); header . add ( \"Name\" ); header . add ( \"Description\" ); header . add ( \"Salary\" ); List < List < Object >> table = new ArrayList <> (); table . add ( Lists . newArrayList ( \"Joe\" , \"Consultant in IT\" , 5000 )); table . add ( Lists . newArrayList ( \"Mary\" , \"Engineer in IT\" , 8000 )); table . add ( Lists . newArrayList ( \"Lina\" , \"Security Expert in IT\" , 9500 )); TablePrinter . print ( table , header , \"%10s %20s %5d\" ); will produce --------------------------------------------------------------------------- Name Description Salary --------------------------------------------------------------------------- Joe Consultant in IT 5000 Mary Engineer in IT 8000 Lina Security Expert in IT 9500 ---------------------------------------------------------------------------","title":"Api"},{"location":"api/#learning-problem","text":"","title":"Learning Problem"},{"location":"api/#description","text":"A learning problem is an object containing of a set of positive uris, negative uris and an optional concept. The positive uris as well as the negative uris are named individuals of the ABox of an OWL Ontology. The concept is a class expression representation of this problem. It is build by concepts of the TBox of the Ontology. The learning problem is described using JSON. An Example: { \"positives\" : [ \"http://ontology.com/individuals/Human1\" , \"http://ontology.com/individuals/Human3\" , \"http://ontology.com/individuals/Human7\" ], \"negatives\" : [ \"http://ontology.com/individuals/Bear1\" , \"http://ontology.com/individuals/Dragon1\" , \"http://ontology.com/individuals/Eagle1\" ], \"concept\" : \"ontology:Human\" }","title":"Description"},{"location":"api/#why-is-the-gold-standard-concept-optional","text":"Be aware: a Learning Problem does not have to contain a Concept. Imagine the following Ontology Class Human Class Dragon Disjoint: Humand, Dragon Human1 is Human Dragon1 is Dragon Human2 is Human Our Learning problem is: positives: [\"Human1\"] negatives: [\"Human2\", \"Dragon1\"] There is no concept within the TBox of the ontology representing the Learning Problem fully.","title":"Why is the gold standard concept optional"},{"location":"api/#api","text":"","title":"API"},{"location":"api/#creating-a-learning-problem","text":"A learning problem can be created using the LearningProblemFactory . We will define positives and negatives each as a Collection<String> for simplicity. These collections contain the positive and negative uris.","title":"Creating a Learning Problem"},{"location":"api/#creating-from-lists","text":"LearningProblem problem = LearningProblemFactory . create ( positives , negatives );","title":"Creating from Lists."},{"location":"api/#creating-from-json-string","text":"String jsonString = \"{ \\\"positives\\\": [...], \\\"negatives\\\": [...] }\" LearningProblem problem = LearningProblemFactory . parse ( jsonString );","title":"Creating from JSON String"},{"location":"api/#creating-multiple-learning-problems-from-json-string","text":"String jsonString = \"[ { \\\"positives\\\": [...], \\\"negatives\\\": [...] }, { \\\"positives\\\": [...], \\\"negatives\\\": [...] }]\" Set < LearningProblem > problems = LearningProblemFactory . readMany ( jsonString );","title":"Creating multiple Learning Problems from JSON String"},{"location":"api/#read-learning-problems-from-file","text":"Set < LearningProblem > problems = LearningProblemFactory . readMany ( new File ( \"learningProblems.json\" ));","title":"Read learning Problems from file"},{"location":"api/#concepts-manchester-parser","text":"","title":"Concepts - Manchester Parser"},{"location":"api/#description_1","text":"A Concept is a Class Expression derived from the TBox of an OWL Ontology. F.e. Human or Dragon describes the Concept of all humans and dragons. The Format used in RAKI ILP is the Manchester Syntax.","title":"Description"},{"location":"api/#api_1","text":"The API has a ManchesterSyntaxParser . This parser allows to parse a Manchester Syntax String to an OWLClassExpression and rendering an OWLClassExpression to a Manchester Syntax String. It needs a main ontology, and an optional OWL base ontology (containing the basics of OWL, such as owl:Thing ). Furhter on it ManchesterSyntaxParser parser = new ManchesterSyntaxParser ( mainOntology , baseOntology ); OWLClassExpression expr = parser . parse ( \"ontology:Human or ontology:Dragon\" ); # concept = ' Human or Dragon ' String concept = parser . render ( expr );","title":"API"},{"location":"api/#benchmark-configuration","text":"","title":"Benchmark Configuration"},{"location":"api/#description_2","text":"The Benchmark Configuration consists of three elements The benchmark name The file path containing the Ontology The file path containing the learning problems Configurations can be read from a YAML file or created simply by using the Configuration constructor The YAML file has to look like this datasets : - name : \"MyBenchmarkName1\" learningProblem : \"/path/to/learningProblems1.json\" dataset : \"/path/to/ontology1.owl\" - name : \"MyBenchmarkName2\" learningProblem : \"/path/to/learningProblems2.json\" dataset : \"/path/to/ontology2.owl\" The Learning problem has to be a json file. An example can be seen above.","title":"Description"},{"location":"api/#api_2","text":"Creating from file //load all Configurations Configurations confs = Configurations . load ( new File ( \"/path/to/config.yml\" )); //retrieve the ones with your benchmark name Configuration myBenchmark = confs . getConfiguration ( \"MyBenchmarkName1\" ); Using the Configuration to retrieve the OWLOntology and the Set of LearningProblems OWLOntology ontology = configuration . readOntology (); Set < LearningProblem > problems = configuration . readLearningProblems ();","title":"API"},{"location":"api/#metrics","text":"Currently, the core can calculate two metrics F1-Measure, Precision and Recall The Concept Length of a Concept","title":"Metrics"},{"location":"api/#f1-measure","text":"The F1 measure will be calculated using the F1MeasureCalculator . The calculator will calculate the f1-score, precision and recall from the true positives , false positives and false negatives provided and stores the results internally as well to calculate the macro and micro f1 measure later on.","title":"F1-Measure"},{"location":"api/#create-an-f1result","text":"F1MeasureCalculator calculator = new F1MeasureCalculator (); F1Result result = calculator . addF1Measure ( truePositives , falsePositives , falseNegatives ); The results can then be queried from the F1Result object double precision = result . getPrecision (); double recall = result . getRecall (); double f1score = result . getF1measure ();","title":"Create an F1Result"},{"location":"api/#create-macro-and-micro-f1-scores","text":"F1MeasureCalculator calculator = new F1MeasureCalculator (); // Calculate and add the F1 scores for some truePositives, falsePositives and falseNegatives calculator . addF1Measure ( truePositives , falsePositives , falseNegatives ); calculator . addF1Measure ( truePositives , falsePositives , falseNegatives ); //the scores will be stored internally and be used to calculate the Micro and Macro F1Measures F1Result macroResults = calculator . calculateMacroF1Measure (); F1Result microResults = calculator . calculateMicroF1Measure (); To clear the stored values use the clear method calculator . clear ();","title":"Create macro and micro F1 scores"},{"location":"api/#concept-length","text":"The concept length of an OWLClassExpression can be calculated by using the ConceptLengthCalculator . Currently, only the following syntax structures are supported: AND OR SOME ALL NOT ConceptLengthCalculator calculator = new ConceptLengthCalculator (); //Create your concept/class expression OWLClassExpression expr = ... ; calculator . render ( expr ); int lengthOfExpr = calculator . getConceptLength ();","title":"Concept Length"},{"location":"api/#evaluator","text":"","title":"Evaluator"},{"location":"api/#description_3","text":"The Evaluator evaluates a set of Learning problems against a set of concepts. Additionally, the Evaluator can evaluate a single Learning Problem against a single concept. The single evaluation will return a ResultContainer containing the F1 Measures and Concept Length. If either the Evaluator was used, by using a set of Learning Problem and Concept pairs or the single evaluation was executed multiple times, the Evaluator can return the Macro and Micro F1 measures as well as all concept lengths. It needs a main Ontology, the owl base Ontology (can be empty though) and if the gold standard concept should be used instead of the positive and negative uris inside the learning problems.","title":"Description"},{"location":"api/#api_3","text":"Create the evaluator boolean useConcepts = false ; Evaluator evaluator = new Evaluator ( mainOntology , owlBaseOntology , useConcepts ); Execute a single execution //create your learning problem LearningProblem problem = ...; //create the answer concept String concept = \"ontology:Human\" ResultContainer container = evaluator . evaluate ( learningProblem , concept ); int conceptLength = container . getConceptLength (); F1Result f1result = container . getF1Result (); Execute multiple LearningProblem, Concept pairs. Each Pair consists of a Learning Problem and the corresponding concept. //Create your problem Pairs Set < Pair < LearningProblem , String >> problemPairs = ...; evaluator . evaluate ( problemPairs ); //Now we can retrieve the macro and micro F1 measures, as well as all Concept Lengths as following F1Result macroF1 = evaluator . getMacroF1Measure (); F1Result microF1 = evaluator . getMicroF1Measure (); List < Integer > conceptLengths = evaluator . getConceptLengths (); Further on all available Metrics can be printed as a table to the standard output using: evaluator . printTable ();","title":"API"},{"location":"api/#table-printer","text":"The TablePrinter is a helper class to print a table in a kinda nice format. List < String > header = new ArrayList <> (); header . add ( \"Name\" ); header . add ( \"Description\" ); header . add ( \"Salary\" ); List < List < Object >> table = new ArrayList <> (); table . add ( Lists . newArrayList ( \"Joe\" , \"Consultant in IT\" , 5000 )); table . add ( Lists . newArrayList ( \"Mary\" , \"Engineer in IT\" , 8000 )); table . add ( Lists . newArrayList ( \"Lina\" , \"Security Expert in IT\" , 9500 )); TablePrinter . print ( table , header , \"%10s %20s %5d\" ); will produce --------------------------------------------------------------------------- Name Description Salary --------------------------------------------------------------------------- Joe Consultant in IT 5000 Mary Engineer in IT 8000 Lina Security Expert in IT 9500 ---------------------------------------------------------------------------","title":"Table Printer"},{"location":"hobbit/add-benchmark/","text":"Add a Benchmark Dataset Preliminaries This involves a few straight forward steps You need to create a URL we call benchmark ID for HOBBIT Add the dataset(s) to this repository and set the configurations accordingly, so the system recognizes your dataset Add the benchmark ID to HOBBIT. Create a BENCHMARK ID Create a benchmark ID like the following http://w3id.org/raki/hobbit/vocab#YOUR-BENCHMARK-NAME we will use YOUR_BENCHMARK_URI as a placeholder fo this ID throughout this README. How to add a Dataset Create the directory where you'll put your benchmark dataset in. cd raki-datagenerator/data/ mkdir YOUR_BENCHMARK_NAME cd YOUR_BENCHMARK_NAME/ Add your Ontology ontology.owl into raki-datagenerator/data/YOUR_BENCHMARK_NAME/ Be aware that your Ontology needs an Ontology ID which you can set in the ontology like the following. Let's assume that your ID is http://example.com/MY-ID Furhter on make sure that the Ontology contains a TBox as well as an ABox. <rdf:RDF xmlns= \"http://example.com/MY-ID\" xml:base= \"http://example.com/MY-ID\" xmlns:rdf= \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" xmlns:owl= \"http://www.w3.org/2002/07/owl#\" xmlns:xml= \"http://www.w3.org/XML/1998/namespace\" xmlns:dl= \"http://dl-learner.org/benchmark/dataset/animals/\" xmlns:xsd= \"http://www.w3.org/2001/XMLSchema#\" xmlns:rdfs= \"http://www.w3.org/2000/01/rdf-schema#\" > <owl:Ontology rdf:about= \"http://example.com/MY-ID\" /> <!-- YOUR ONTOLOGY HERE --> </rdf:RDF> Now create a file called lp.json where you put the learning problems in the following format: [ { \"positives\" : [ \"http://example.com/positive1\" , \"http://example.com/positive2\" ... ], \"negatives\" : [ \"http://example.com/negative1\" , \"http://example.com/negative2\" ... ] }, ... ] Add the dataset to the benchmark configuration Edit raki-datagenerator/src/main/resources/benchmark.yaml and add the following at the end - name : \"YOUR_BENCHMARK_URI\" dataset : \"/raki/data/YOUR-BENCHMARK-NAME/ontology.owl\" learningProblem : \"/raki/data/YOUR-BENCHMARK-NAME/lp.json\" Add the dataset to HOBBIT This is the only step which is public. go to https://git.project-hobbit.eu/raki/raki-private/raki-benchmark and edit the benchmark.ttl Add the following to the end <YOUR_BENCHMARK_URI> a raki : Datasets; rdfs : label \"My Benchmark Name\"@en; rdfs : comment \"Description of My Benchmark Name\"@en . Be aware: Folks may see the name of the dataset. (Use an obscured one if you don't want them, however it needs to be obscured in the previous steps as well.) Use Ontolearn as a system Get pre defined embeddings and trained datasets cd raki-system-adapters && https://github.com/dice-group/DRILL/blob/main/embeddings.zip?raw=true -O embeddings.zip && cd .. cd raki-system-adapters && https://github.com/dice-group/DRILL/blob/main/pre_trained_agents.zip?raw=true -O pre_trained_agents.zip && cd .. Unzip them to add your datasets cd raki-system-adapters && unzip embeddings.zip && cd .. cd raki-system-adapters && unzip pre_trained_agents.zip && cd .. To use the Ontolearn adapter you need to create embeddings in https://github.com/dice-group/DAIKIRI-Embedding using ConEx on your dataset. add the embeddings and pre-trained agents to the corresponding folder in embeddings/ConEx_YOUR_DATASET_NAME/ConEx_entity_embeddings.csv and pre_trained_agents/YOUR_DATASET_NAME/DrillHeuristic_averaging/DrillHeuristic_averaging.pth Add in raki-system-adapter/src/main/resources/drill-mapping.properties using your previous declared Ontology ID (e.g. http://example.com/MY-ID ) http\\ : //example.com/MY-ID=ConEx_YOUR_DATASET_NAME/ConEx_entity_embeddings.csv, YOUR_DATASET_NAME/DrillHeuristic_averaging/DrillHeuristic_averaging.pth Now we need to zip the embeddings and pre_trained_agents again cd raki-system-adapters && zip -r pre_trained_agents.zip pre_trained_agents/ && cd .. cd raki-system-adapters && zip -r embeddings.zip embeddings/ && cd ..","title":"Add benchmark"},{"location":"hobbit/add-benchmark/#add-a-benchmark-dataset","text":"","title":"Add a Benchmark Dataset"},{"location":"hobbit/add-benchmark/#preliminaries","text":"This involves a few straight forward steps You need to create a URL we call benchmark ID for HOBBIT Add the dataset(s) to this repository and set the configurations accordingly, so the system recognizes your dataset Add the benchmark ID to HOBBIT.","title":"Preliminaries"},{"location":"hobbit/add-benchmark/#create-a-benchmark-id","text":"Create a benchmark ID like the following http://w3id.org/raki/hobbit/vocab#YOUR-BENCHMARK-NAME we will use YOUR_BENCHMARK_URI as a placeholder fo this ID throughout this README.","title":"Create a BENCHMARK ID"},{"location":"hobbit/add-benchmark/#how-to-add-a-dataset","text":"Create the directory where you'll put your benchmark dataset in. cd raki-datagenerator/data/ mkdir YOUR_BENCHMARK_NAME cd YOUR_BENCHMARK_NAME/ Add your Ontology ontology.owl into raki-datagenerator/data/YOUR_BENCHMARK_NAME/ Be aware that your Ontology needs an Ontology ID which you can set in the ontology like the following. Let's assume that your ID is http://example.com/MY-ID Furhter on make sure that the Ontology contains a TBox as well as an ABox. <rdf:RDF xmlns= \"http://example.com/MY-ID\" xml:base= \"http://example.com/MY-ID\" xmlns:rdf= \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" xmlns:owl= \"http://www.w3.org/2002/07/owl#\" xmlns:xml= \"http://www.w3.org/XML/1998/namespace\" xmlns:dl= \"http://dl-learner.org/benchmark/dataset/animals/\" xmlns:xsd= \"http://www.w3.org/2001/XMLSchema#\" xmlns:rdfs= \"http://www.w3.org/2000/01/rdf-schema#\" > <owl:Ontology rdf:about= \"http://example.com/MY-ID\" /> <!-- YOUR ONTOLOGY HERE --> </rdf:RDF> Now create a file called lp.json where you put the learning problems in the following format: [ { \"positives\" : [ \"http://example.com/positive1\" , \"http://example.com/positive2\" ... ], \"negatives\" : [ \"http://example.com/negative1\" , \"http://example.com/negative2\" ... ] }, ... ]","title":"How to add a Dataset"},{"location":"hobbit/add-benchmark/#add-the-dataset-to-the-benchmark-configuration","text":"Edit raki-datagenerator/src/main/resources/benchmark.yaml and add the following at the end - name : \"YOUR_BENCHMARK_URI\" dataset : \"/raki/data/YOUR-BENCHMARK-NAME/ontology.owl\" learningProblem : \"/raki/data/YOUR-BENCHMARK-NAME/lp.json\"","title":"Add the dataset to the benchmark configuration"},{"location":"hobbit/add-benchmark/#add-the-dataset-to-hobbit","text":"This is the only step which is public. go to https://git.project-hobbit.eu/raki/raki-private/raki-benchmark and edit the benchmark.ttl Add the following to the end <YOUR_BENCHMARK_URI> a raki : Datasets; rdfs : label \"My Benchmark Name\"@en; rdfs : comment \"Description of My Benchmark Name\"@en . Be aware: Folks may see the name of the dataset. (Use an obscured one if you don't want them, however it needs to be obscured in the previous steps as well.)","title":"Add the dataset to HOBBIT"},{"location":"hobbit/add-benchmark/#use-ontolearn-as-a-system","text":"Get pre defined embeddings and trained datasets cd raki-system-adapters && https://github.com/dice-group/DRILL/blob/main/embeddings.zip?raw=true -O embeddings.zip && cd .. cd raki-system-adapters && https://github.com/dice-group/DRILL/blob/main/pre_trained_agents.zip?raw=true -O pre_trained_agents.zip && cd .. Unzip them to add your datasets cd raki-system-adapters && unzip embeddings.zip && cd .. cd raki-system-adapters && unzip pre_trained_agents.zip && cd .. To use the Ontolearn adapter you need to create embeddings in https://github.com/dice-group/DAIKIRI-Embedding using ConEx on your dataset. add the embeddings and pre-trained agents to the corresponding folder in embeddings/ConEx_YOUR_DATASET_NAME/ConEx_entity_embeddings.csv and pre_trained_agents/YOUR_DATASET_NAME/DrillHeuristic_averaging/DrillHeuristic_averaging.pth Add in raki-system-adapter/src/main/resources/drill-mapping.properties using your previous declared Ontology ID (e.g. http://example.com/MY-ID ) http\\ : //example.com/MY-ID=ConEx_YOUR_DATASET_NAME/ConEx_entity_embeddings.csv, YOUR_DATASET_NAME/DrillHeuristic_averaging/DrillHeuristic_averaging.pth Now we need to zip the embeddings and pre_trained_agents again cd raki-system-adapters && zip -r pre_trained_agents.zip pre_trained_agents/ && cd .. cd raki-system-adapters && zip -r embeddings.zip embeddings/ && cd ..","title":"Use Ontolearn as a system"},{"location":"hobbit/add-system/","text":"Add A System In this section we described how you can add your RAKI ILP system to Hobbit We assume that you directly extend the raki-system-adapter module. Otherwise you need to add the following dependency to your system <dependency> <groupId> org.dice_group.raki </groupId> <artifactId> raki-hobbit </artifactId> <version> 1.0.0-SNAPSHOT </version> </dependency> Create your System There are two ways, either the system has a Java API, or the system has an HTTP endpoint Using the Java API This way you need to implement two methods public class MySystem extends AbstractRakiSystemAdapter { @Override public String createConcept ( String posNegExample ) throws IOException , Exception { LearningProblem problem = LearningProblem . create ( posNegExample ); //TODO your concept learning //return your concept in manchester syntax return concept ; } @Override public void loadOntology ( File ontologyFile ) throws IOException , Exception { //TODO load the ontology here. } } Using HTTP If you're using an HTTP concept learner you need to implement mainly one function, the function to start the system. public class MySystem extends AbstractHTTPSystemAdapter { private static final String baseUri = \"http://localhost:9080\" ; @Override protected String convertToManchester ( String concept ) throws OWLOntologyCreationException , IOException { //TODO this can be used if your system doesn't provide manchester syntax directly return concept ; } public MySystem () { super ( baseUri ); } @Override public void startSystem ( String ontologyFile ) throws Exception { //TODO start and load your system using the ontology file // Be aware that the AbstractHTTPSystemAdapter waits until the system provides the status ready // and you don't have to implement that } } Additionally, The HTTP endpoint needs to implement the following two paths GET /status POST /concept_learning Status the status endpoint needs return if the Concept Learner is ready to be queried. It should return an HTTPCode 200 and the following json message if that is the case { \"status\" : \"ready\" } Concept_learning The concept_learner will need to accept a Learning Problem in JSON format as a POST request and should return the concept for this problem. Ideally the concept will be directly in manchester syntax, if that is not the case however it is possible to convert the concept to manchster syntax inside the System wrapper itself by overriding the following method @Override protected String convertToManchester ( String concept ) throws OWLOntologyCreationException , IOException { //TODO this can be used if your system doesn't provide manchester syntax directly return concept ; } Add System to Hobbit Now that we create that system we can add it to Hobbit Create a system.ttl Create a repository in https://git.project-hobbit.eu with the following system.ttl @ prefix rdfs : < http : // www . w3 . org / 2000 / 01 / rdf - schema # > . @ prefix hobbit : < http : // w3id . org / hobbit / vocab # > . @ prefix raki : < http : // w3id . org / raki / hobbit / vocab # > . raki : MySystem a hobbit : SystemInstance ; rdfs : label \" MySystem \" @ en ; rdfs : comment \" The MySystem system \" @ en ; hobbit : imageName \" git.project-hobbit.eu:4567/raki/mySystem \" ; hobbit : implementsAPI raki : Private - API , raki : API . Create the Docker container Now we can create a Dockerfile, build and push that docker container to the Hobbit registry The Dockerfile should look like FROM java ADD target/raki-system-adapter-1.0.0-SNAPSHOT.jar /raki/systems.jar WORKDIR /raki CMD java -cp systems.jar org.hobbit.core.run.ComponentStarter org.dice_group.raki.hobbit.systems.test.TestSystem However, as long as the system is executed the same way as the last line you can do whatever before Now let's build the docker container docker build -f Dockerfile -t IMAGE_NAME . Be aware that the Image name is predetermined by your repository. if your repository is located at https://git.project-hobbit.eu/raki/mysystem your Image name will be git.project-hobbit.eu:4567/raki/mysystem If you're using a local deployment of Hobbit that's it (make sure that you set DOCKER_AUTOPULL to 0 in the Hobbit platform) If you want to use the system on the https://master.project-hobbit.eu push the repository docker push IMAGE_NAME If that doesn't work make sure that you used docker login to login to the Docker Hobbit registry","title":"Add A System"},{"location":"hobbit/add-system/#add-a-system","text":"In this section we described how you can add your RAKI ILP system to Hobbit We assume that you directly extend the raki-system-adapter module. Otherwise you need to add the following dependency to your system <dependency> <groupId> org.dice_group.raki </groupId> <artifactId> raki-hobbit </artifactId> <version> 1.0.0-SNAPSHOT </version> </dependency>","title":"Add A System"},{"location":"hobbit/add-system/#create-your-system","text":"There are two ways, either the system has a Java API, or the system has an HTTP endpoint","title":"Create your System"},{"location":"hobbit/add-system/#using-the-java-api","text":"This way you need to implement two methods public class MySystem extends AbstractRakiSystemAdapter { @Override public String createConcept ( String posNegExample ) throws IOException , Exception { LearningProblem problem = LearningProblem . create ( posNegExample ); //TODO your concept learning //return your concept in manchester syntax return concept ; } @Override public void loadOntology ( File ontologyFile ) throws IOException , Exception { //TODO load the ontology here. } }","title":"Using the Java API"},{"location":"hobbit/add-system/#using-http","text":"If you're using an HTTP concept learner you need to implement mainly one function, the function to start the system. public class MySystem extends AbstractHTTPSystemAdapter { private static final String baseUri = \"http://localhost:9080\" ; @Override protected String convertToManchester ( String concept ) throws OWLOntologyCreationException , IOException { //TODO this can be used if your system doesn't provide manchester syntax directly return concept ; } public MySystem () { super ( baseUri ); } @Override public void startSystem ( String ontologyFile ) throws Exception { //TODO start and load your system using the ontology file // Be aware that the AbstractHTTPSystemAdapter waits until the system provides the status ready // and you don't have to implement that } } Additionally, The HTTP endpoint needs to implement the following two paths GET /status POST /concept_learning","title":"Using HTTP"},{"location":"hobbit/add-system/#status","text":"the status endpoint needs return if the Concept Learner is ready to be queried. It should return an HTTPCode 200 and the following json message if that is the case { \"status\" : \"ready\" }","title":"Status"},{"location":"hobbit/add-system/#concept_learning","text":"The concept_learner will need to accept a Learning Problem in JSON format as a POST request and should return the concept for this problem. Ideally the concept will be directly in manchester syntax, if that is not the case however it is possible to convert the concept to manchster syntax inside the System wrapper itself by overriding the following method @Override protected String convertToManchester ( String concept ) throws OWLOntologyCreationException , IOException { //TODO this can be used if your system doesn't provide manchester syntax directly return concept ; }","title":"Concept_learning"},{"location":"hobbit/add-system/#add-system-to-hobbit","text":"Now that we create that system we can add it to Hobbit","title":"Add System to Hobbit"},{"location":"hobbit/add-system/#create-a-systemttl","text":"Create a repository in https://git.project-hobbit.eu with the following system.ttl @ prefix rdfs : < http : // www . w3 . org / 2000 / 01 / rdf - schema # > . @ prefix hobbit : < http : // w3id . org / hobbit / vocab # > . @ prefix raki : < http : // w3id . org / raki / hobbit / vocab # > . raki : MySystem a hobbit : SystemInstance ; rdfs : label \" MySystem \" @ en ; rdfs : comment \" The MySystem system \" @ en ; hobbit : imageName \" git.project-hobbit.eu:4567/raki/mySystem \" ; hobbit : implementsAPI raki : Private - API , raki : API .","title":"Create a system.ttl"},{"location":"hobbit/add-system/#create-the-docker-container","text":"Now we can create a Dockerfile, build and push that docker container to the Hobbit registry The Dockerfile should look like FROM java ADD target/raki-system-adapter-1.0.0-SNAPSHOT.jar /raki/systems.jar WORKDIR /raki CMD java -cp systems.jar org.hobbit.core.run.ComponentStarter org.dice_group.raki.hobbit.systems.test.TestSystem However, as long as the system is executed the same way as the last line you can do whatever before Now let's build the docker container docker build -f Dockerfile -t IMAGE_NAME . Be aware that the Image name is predetermined by your repository. if your repository is located at https://git.project-hobbit.eu/raki/mysystem your Image name will be git.project-hobbit.eu:4567/raki/mysystem If you're using a local deployment of Hobbit that's it (make sure that you set DOCKER_AUTOPULL to 0 in the Hobbit platform) If you want to use the system on the https://master.project-hobbit.eu push the repository docker push IMAGE_NAME If that doesn't work make sure that you used docker login to login to the Docker Hobbit registry","title":"Create the Docker container"},{"location":"hobbit/overview/","text":"In this section we will explain the overview of Hobbit. Usage Go to https://git.project-hobbit.eu Login Go to Benchmarks Choose Raki ILP Benchmark or Raki ILP Benchmark - Priv Choose the system you want to benchmark set the parameters you want to use (see below) choose the benchmark you want to execute (benchmark name) Execute Parameters The Hobbit frontend allows a few parameters to be used. Name Description Default Benchmark name The Benchmark Name to use Timeout in MS The timeout to use in MS for each learning problem 60000 (1min) Ratio of positives to system should receive Will randomly choose the specified percentage (0.0, 1.0) of positive uris. 1.0 Minimum Examples if ratio is set < 1 the minimum amount of positive examples that should remain of splitRatio is smaller than 1 5 Seed Seed to use for any random activity 123 Workflow The following image shows the time flow of the Raki Hobbit Modules The RakiBenchmark and the RakiSystem will be created by the Hobbit System. After that the RakiBenchmark creates the RakiTaskGenerator, the RakiDatagenerator and the RakiEvaluation. The init phase of Hobbit ends and the RakiSystem and the RakiEvaluator needs the Ontology they should use. The RakiDataGenerator will load the Ontology to be used and sends it to the RakiSystem and the RakiEvaluator. To assure that it has fully send the Ontology, the RakiDataGenerator will then send a command to both modules, indicating it has fully send the ontology. The RakiSystem and the RakiEvaluator will then load the ontology and each sends a command to the RakiTaskGenerator indicating they have loaded the Ontology and are readyto go. In the same time, the RakiDataGenerator will send the RakiTaskGenerator the LearningProblems to the RakiTaskGenerator. Each LearningProblem is one task and thus the DataGenerator will send each LearningProblem, and not all at once. Be aware that the image simplifies this. As soon as the RakiTaskGenerator got the Ontology loaded commands it will send the Learning problem to the system (without a gold standard concept) and the full learning problem to the RakiEvaluator. Be aware that the image simplifies this by simply sending all learning problems instead of each one by one. The RakiSystem will then send the concept it generated from the learning problem to the evaluation storage (which will then be send to the evaluator). After the RakiTaskGeneratir and RakiSystem finished their tasks, the RakiBenchmark controller will send a command to the RakiEvaluator to start the evaluation. (This is needed, as the RakiEvaluator sometimes ended prematurely) As soon as the RakiEvaluator finished evaluation, it will send the Result model to the RakiBenchmark Controller.","title":"Overview"},{"location":"hobbit/overview/#usage","text":"Go to https://git.project-hobbit.eu Login Go to Benchmarks Choose Raki ILP Benchmark or Raki ILP Benchmark - Priv Choose the system you want to benchmark set the parameters you want to use (see below) choose the benchmark you want to execute (benchmark name) Execute","title":"Usage"},{"location":"hobbit/overview/#parameters","text":"The Hobbit frontend allows a few parameters to be used. Name Description Default Benchmark name The Benchmark Name to use Timeout in MS The timeout to use in MS for each learning problem 60000 (1min) Ratio of positives to system should receive Will randomly choose the specified percentage (0.0, 1.0) of positive uris. 1.0 Minimum Examples if ratio is set < 1 the minimum amount of positive examples that should remain of splitRatio is smaller than 1 5 Seed Seed to use for any random activity 123","title":"Parameters"},{"location":"hobbit/overview/#workflow","text":"The following image shows the time flow of the Raki Hobbit Modules The RakiBenchmark and the RakiSystem will be created by the Hobbit System. After that the RakiBenchmark creates the RakiTaskGenerator, the RakiDatagenerator and the RakiEvaluation. The init phase of Hobbit ends and the RakiSystem and the RakiEvaluator needs the Ontology they should use. The RakiDataGenerator will load the Ontology to be used and sends it to the RakiSystem and the RakiEvaluator. To assure that it has fully send the Ontology, the RakiDataGenerator will then send a command to both modules, indicating it has fully send the ontology. The RakiSystem and the RakiEvaluator will then load the ontology and each sends a command to the RakiTaskGenerator indicating they have loaded the Ontology and are readyto go. In the same time, the RakiDataGenerator will send the RakiTaskGenerator the LearningProblems to the RakiTaskGenerator. Each LearningProblem is one task and thus the DataGenerator will send each LearningProblem, and not all at once. Be aware that the image simplifies this. As soon as the RakiTaskGenerator got the Ontology loaded commands it will send the Learning problem to the system (without a gold standard concept) and the full learning problem to the RakiEvaluator. Be aware that the image simplifies this by simply sending all learning problems instead of each one by one. The RakiSystem will then send the concept it generated from the learning problem to the evaluation storage (which will then be send to the evaluator). After the RakiTaskGeneratir and RakiSystem finished their tasks, the RakiBenchmark controller will send a command to the RakiEvaluator to start the evaluation. (This is needed, as the RakiEvaluator sometimes ended prematurely) As soon as the RakiEvaluator finished evaluation, it will send the Result model to the RakiBenchmark Controller.","title":"Workflow"},{"location":"hobbit/setup/","text":"RAKI ILP Benchmark integration for HOBBIT. This setup will guide you through the steps to create the RAKI ILP Benchmark on your local machine using a local Hobbit. Preparations You need an Account on Hobbit at https://git.project-hobbit.eu and permission on the project You need to use a local HOBBIT deployment if you want to use private datasets You need to Clone this Repository 2. Use a local HOBBIT deployment See https://hobbit-project.github.io/quick_guide.html how to deploy HOBBIT locally and make sure to set DOCKER_AUTOPULL: 0 in the config as described in https://hobbit-project.github.io/parameters_env.html services : platform-controller : image : hobbitproject/hobbit-platform-controller:latest networks : - hobbit - hobbit-core environment : ... DOCKER_AUTOPULL : 0 3. Clone this Repo git clone https://github.com/dice-group/raki-ilp-benchmark cd raki-ilp-benchmark git checkout raki-private Add a Dataset Please see Add a Benchmark to Hobbit Build Set build.sh to an executable chmod +x build.sh If you've done your changes: ./build.sh It will automatically build the Docker images for the private RAKI benchmark. Access Raki-private As the RAKI-private benchmark should be only accessible by members of the raki-private group add to the docker-compose.yml the following services : platform-controller : image : hobbitproject/hobbit-platform-controller:latest networks : - hobbit - hobbit-core environment : ... GITLAB_USER : \"YOUR_USER_NAME\" GITLAB_EMAIL : \"YOUR_EMAIL\" GITLAB_TOKEN : \"YOUR_TOKEN\" YOUR_TOKEN is a gitlab token you have to create in https://git.project-hobbit.eu -> Settings -> Access Token -> check at least (api, read_repository, read_registry) Now start the platform and go to http://localhost:8181 (Keycloack) -> Admin Console and login using the Keycloack admin account (see https://hobbit-project.github.io/quick_guide.html for initial credentials) Now add a dummy user (users -> add users) with the same name and email as your token user. Click again on Users and on view all users click on the ID of your newly created dummy user and click on the Credentials tab. Create a password for your user. Now you can login into localhost:8080 using your dummy user and should be able to access the Raki ILP Benchmark - Priv .","title":"Setup"},{"location":"hobbit/setup/#preparations","text":"You need an Account on Hobbit at https://git.project-hobbit.eu and permission on the project You need to use a local HOBBIT deployment if you want to use private datasets You need to Clone this Repository","title":"Preparations"},{"location":"hobbit/setup/#2-use-a-local-hobbit-deployment","text":"See https://hobbit-project.github.io/quick_guide.html how to deploy HOBBIT locally and make sure to set DOCKER_AUTOPULL: 0 in the config as described in https://hobbit-project.github.io/parameters_env.html services : platform-controller : image : hobbitproject/hobbit-platform-controller:latest networks : - hobbit - hobbit-core environment : ... DOCKER_AUTOPULL : 0","title":"2. Use a local HOBBIT deployment"},{"location":"hobbit/setup/#3-clone-this-repo","text":"git clone https://github.com/dice-group/raki-ilp-benchmark cd raki-ilp-benchmark git checkout raki-private","title":"3. Clone this Repo"},{"location":"hobbit/setup/#add-a-dataset","text":"Please see Add a Benchmark to Hobbit","title":"Add a Dataset"},{"location":"hobbit/setup/#build","text":"Set build.sh to an executable chmod +x build.sh If you've done your changes: ./build.sh It will automatically build the Docker images for the private RAKI benchmark.","title":"Build"},{"location":"hobbit/setup/#access-raki-private","text":"As the RAKI-private benchmark should be only accessible by members of the raki-private group add to the docker-compose.yml the following services : platform-controller : image : hobbitproject/hobbit-platform-controller:latest networks : - hobbit - hobbit-core environment : ... GITLAB_USER : \"YOUR_USER_NAME\" GITLAB_EMAIL : \"YOUR_EMAIL\" GITLAB_TOKEN : \"YOUR_TOKEN\" YOUR_TOKEN is a gitlab token you have to create in https://git.project-hobbit.eu -> Settings -> Access Token -> check at least (api, read_repository, read_registry) Now start the platform and go to http://localhost:8181 (Keycloack) -> Admin Console and login using the Keycloack admin account (see https://hobbit-project.github.io/quick_guide.html for initial credentials) Now add a dummy user (users -> add users) with the same name and email as your token user. Click again on Users and on view all users click on the ID of your newly created dummy user and click on the Credentials tab. Create a password for your user. Now you can login into localhost:8080 using your dummy user and should be able to access the Raki ILP Benchmark - Priv .","title":"Access Raki-private"}]}